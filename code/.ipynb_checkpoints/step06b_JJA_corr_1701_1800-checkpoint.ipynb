{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is one in a series of scripts that will calculate, for specific centuries, correlations between GHD-Core and the Pauling, Luterbacher, and OWDA reconstructions.\n",
    "\n",
    "* Spearman's rank correlations.\n",
    "* This script is specific for years:\n",
    "#### 1701-1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup the Analysis\n",
    "import calendar\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "import matplotlib\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "from IPython.display import display\n",
    "\n",
    "# Embeds plots inside the notebook (use in iPython Notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "# Rectangle Boundaries\n",
    "lonmin=-2; lonmax=8; latmin=43; latmax=51;\n",
    "\n",
    "# For plotting a rectangle on the maps\n",
    "def plot_rectangle(bmap, lonmin,lonmax,latmin,latmax):\n",
    "    xs = [lonmin,lonmax,lonmax,lonmin,lonmin]\n",
    "    ys = [latmin,latmin,latmax,latmax,latmin]\n",
    "    bmap.plot(xs, ys,latlon = True, color='k', linestyle='--', linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the GHD data and the individual climate reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and properly format wine data\n",
    "infile= '../data/ghd_anom_doy_v02.csv'   # Name of the original data file\n",
    "\n",
    "df=pd.read_csv(infile)\n",
    "\n",
    "# GHD Data to Analyze\n",
    "ghd_name = 'GHDcore'\n",
    "\n",
    "# Pull out year and mean as float64\n",
    "yr       = np.int64(df.Year)\n",
    "ghd_mean = np.float64(df[ghd_name])\n",
    "\n",
    "#%%############################################################################\n",
    "# Load OWDA Data\n",
    "ncfile_owda = netCDF4.Dataset('/Users/bcook/Documents/GEODATA/OWDA/owda_hd_fix1_500.nc')\n",
    "\n",
    "# Load OWDA Variables\n",
    "lat_pdsi=ncfile_owda.variables['lat'][:];\n",
    "lon_pdsi=ncfile_owda.variables['lon'][:];\n",
    "yr_pdsi=ncfile_owda.variables['time'][:];\n",
    "pdsi=ncfile_owda.variables['pdsi'][:];\n",
    "\n",
    "# Swap PDSI axes so orientation is correct: time, lat, lon\n",
    "pdsi=np.swapaxes(pdsi,0,2)\n",
    "\n",
    "# close file\n",
    "ncfile_owda.close\n",
    "\n",
    "#%%############################################################################\n",
    "# Load Luterbacher Temp Data\n",
    "ncfile_luter = netCDF4.Dataset('/Users/bcook/Documents/GEODATA/LUTERTEMP/LuterbacherTemp.nc')\n",
    "\n",
    "# Load Variables\n",
    "lat_temp=ncfile_luter.variables['lat'][:];\n",
    "lon_temp=ncfile_luter.variables['lon'][:];\n",
    "\n",
    "# Luter is a seasonal temperature reconstruction, so create seasonal and year vectors\n",
    "# 1=DJF, 2=MAM, 3=JJA, 4=SON\n",
    "seas_luter = np.arange(1,5); seas_luter_all = np.transpose(np.tile(seas_luter,(1,503)))\n",
    "yr_luter  = np.arange(1500,2003); \n",
    "\n",
    "# Now, pull out each season individually\n",
    "tmp_locs = np.where(seas_luter_all==1); tmp_locs = tmp_locs[0]; tmp_DJF = ncfile_luter.variables['temp'][tmp_locs,0,:,:] \n",
    "tmp_locs = np.where(seas_luter_all==2); tmp_locs = tmp_locs[0]; tmp_MAM = ncfile_luter.variables['temp'][tmp_locs,0,:,:] \n",
    "tmp_locs = np.where(seas_luter_all==3); tmp_locs = tmp_locs[0]; tmp_JJA = ncfile_luter.variables['temp'][tmp_locs,0,:,:]\n",
    "tmp_locs = np.where(seas_luter_all==4); tmp_locs = tmp_locs[0]; tmp_SON = ncfile_luter.variables['temp'][tmp_locs,0,:,:]\n",
    "\n",
    "# close file\n",
    "ncfile_luter.close\n",
    "\n",
    "#%%############################################################################\n",
    "# Load Pauling Precip Data\n",
    "ncfile_pauling = netCDF4.Dataset('/Users/bcook/Documents/GEODATA/PAULINGPREC/PaulingPrecip.nc')\n",
    "\n",
    "# Load Variables\n",
    "lat_prec=ncfile_pauling.variables['lat'][:];\n",
    "lon_prec=ncfile_pauling.variables['lon'][:];\n",
    "\n",
    "# Luter is a seasonal temperature reconstruction, so create seasonal and year vectors\n",
    "# 1=DJF, 2=MAM, 3=JJA, 4=SON\n",
    "seas_paul = np.arange(1,5); seas_paul_all = np.transpose(np.tile(seas_luter,(1,501)))\n",
    "yr_paul  = np.arange(1500,2001); \n",
    "\n",
    "# Now, pull out each season individually\n",
    "pre_locs = np.where(seas_paul_all==1); pre_locs = pre_locs[0]; pre_DJF = ncfile_pauling.variables['precip'][pre_locs,0,:,:] \n",
    "pre_locs = np.where(seas_paul_all==2); pre_locs = pre_locs[0]; pre_MAM = ncfile_pauling.variables['precip'][pre_locs,0,:,:] \n",
    "pre_locs = np.where(seas_paul_all==3); pre_locs = pre_locs[0]; pre_JJA = ncfile_pauling.variables['precip'][pre_locs,0,:,:]\n",
    "pre_locs = np.where(seas_paul_all==4); pre_locs = pre_locs[0]; pre_SON = ncfile_pauling.variables['precip'][pre_locs,0,:,:]\n",
    "\n",
    "# close file\n",
    "ncfile_pauling.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, for each century, pull out all the GHD and climate data and conduct point by point correlations. In this way, we can see if the relationships are stationary. This may be especially important for pre- and post- 1900, when there are significant root stock changes in the wineries.\n",
    "* Setup up base period and pool out the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Base period to conduct correlations over. Remember, last year you want, add one.\n",
    "base_period = np.arange(1701,1801)   \n",
    "\n",
    "# Now, find these year locations in each dataset\n",
    "i_yr_ghd  = np.where( (yr>=np.min(base_period))       & (yr<=np.max(base_period)))[0]\n",
    "i_yr_temp = np.where( (yr_luter>=np.min(base_period)) & (yr_luter<=np.max(base_period)))[0]\n",
    "i_yr_prec = np.where( (yr_paul>=np.min(base_period))  & (yr_paul<=np.max(base_period)))[0]\n",
    "i_yr_pdsi = np.where( (yr_pdsi>=np.min(base_period))  & (yr_pdsi<=np.max(base_period)))[0]\n",
    "\n",
    "# Now, subset the data\n",
    "sub_ghd  = ghd_mean[i_yr_ghd]\n",
    "sub_temp = tmp_JJA[i_yr_temp,:,:]\n",
    "sub_prec = pre_JJA[i_yr_prec,:,:]\n",
    "sub_pdsi = pdsi[i_yr_pdsi,:,:]\n",
    "\n",
    "# Arrays to store regional average PDSI/Temp/Precip for each site\n",
    "pdsi_coswtmean = np.zeros((np.size(base_period)))\n",
    "tmp_coswtmean  = np.zeros((np.size(base_period)))\n",
    "pre_coswtmean  = np.zeros((np.size(base_period)))\n",
    "\n",
    "# Latitude/Longitude range for averaging\n",
    "print(\"lat range = (\"+np.str(latmin)+\" to \"+np.str(latmax)+\")\")\n",
    "print(\"lon range = (\"+np.str(lonmin)+\" to \"+np.str(lonmax)+\")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create regional average series of Temp, Prec, and PDSI over the core region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEMPERATURE----------------------------------------------------------------------------------------------------------\n",
    "i_lat_reg = np.where((lat_temp>=latmin) & (lat_temp<=latmax))[0]; lat_reg = lat_temp[i_lat_reg]\n",
    "i_lon_reg = np.where((lon_temp>=lonmin) & (lon_temp<=lonmax))[0]; lon_reg = lon_temp[i_lon_reg]\n",
    "\n",
    "# Create Latitude Weights\n",
    "lat_wts = scipy.cos(scipy.deg2rad(lat_reg));\n",
    "lat_wts_grid,lon_junk = np.meshgrid(lat_wts,lon_reg)\n",
    "lat_wts_grid=np.swapaxes(lat_wts_grid,1,0)\n",
    "        \n",
    "# Load Each Year and Spatially Average\n",
    "for i_yr in enumerate(base_period):\n",
    "    #print(i_yr)\n",
    "    # Pull out Current Month Temp/Precip\n",
    "    temp_curr = sub_temp[i_yr[0],i_lat_reg,:][:,i_lon_reg]\n",
    "        \n",
    "    # Cosine Weighted Average\n",
    "    tmp_coswtmean[i_yr[0]]  = np.ma.average(np.ma.masked_invalid(temp_curr),weights=lat_wts_grid)\n",
    "\n",
    "# PRECIPITATION--------------------------------------------------------------------------------------------------------\n",
    "i_lat_reg = np.where((lat_prec>=latmin) & (lat_prec<=latmax))[0]; lat_reg = lat_prec[i_lat_reg]\n",
    "i_lon_reg = np.where((lon_prec>=lonmin) & (lon_prec<=lonmax))[0]; lon_reg = lon_prec[i_lon_reg]\n",
    "\n",
    "# Create Latitude Weights\n",
    "lat_wts = scipy.cos(scipy.deg2rad(lat_reg));\n",
    "lat_wts_grid,lon_junk = np.meshgrid(lat_wts,lon_reg)\n",
    "lat_wts_grid=np.swapaxes(lat_wts_grid,1,0)\n",
    "        \n",
    "# Load Each Year and Spatially Average\n",
    "for i_yr in enumerate(base_period):\n",
    "    #print(i_yr)\n",
    "    # Pull out Current Month Temp/Precip\n",
    "    prec_curr = sub_prec[i_yr[0],i_lat_reg,:][:,i_lon_reg]\n",
    "        \n",
    "    # Cosine Weighted Average\n",
    "    pre_coswtmean[i_yr[0]]  = np.ma.average(np.ma.masked_invalid(prec_curr),weights=lat_wts_grid)\n",
    "    \n",
    "# PDSI--------------------------------------------------------------------------------------------------------\n",
    "i_lat_reg = np.where((lat_pdsi>=latmin) & (lat_pdsi<=latmax))[0]; lat_reg = lat_pdsi[i_lat_reg]\n",
    "i_lon_reg = np.where((lon_pdsi>=lonmin) & (lon_pdsi<=lonmax))[0]; lon_reg = lon_pdsi[i_lon_reg]\n",
    "\n",
    "# Create Latitude Weights\n",
    "lat_wts               = scipy.cos(scipy.deg2rad(lat_reg));\n",
    "lat_wts_grid,lon_junk = np.meshgrid(lat_wts,lon_reg)\n",
    "lat_wts_grid          = np.swapaxes(lat_wts_grid,1,0)\n",
    "        \n",
    "# Load Each Year and Spatially Average\n",
    "for i_yr in enumerate(base_period):\n",
    "    #print(i_yr)\n",
    "    # Pull out Current Month Temp/Precip\n",
    "    pdsi_curr = sub_pdsi[i_yr[0],i_lat_reg,:][:,i_lon_reg]\n",
    "        \n",
    "    # Cosine Weighted Average\n",
    "    pdsi_coswtmean[i_yr[0]]  = np.ma.average(np.ma.masked_invalid(pdsi_curr),weights=lat_wts_grid)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Regression Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Data Frame first to store the data\n",
    "df_siteclim = pd.DataFrame(index=base_period, columns=['GHD','Temp','Prec','PDSI'])\n",
    "    \n",
    "# Populate Dataframe for regression plots\n",
    "df_siteclim.GHD  = np.float64(sub_ghd)\n",
    "df_siteclim.Temp = np.float64(tmp_coswtmean)\n",
    "df_siteclim.Prec = np.float64(pre_coswtmean)\n",
    "df_siteclim.PDSI = np.float64(pdsi_coswtmean)  \n",
    "\n",
    "# Axis Limits\n",
    "limit_ghd=np.float64([-35,25]); \n",
    "limit_temp=np.float64([14,21]); \n",
    "limit_prec=np.float64([50,375]); \n",
    "limit_pdsi=np.float64([-5,4]);\n",
    "    \n",
    "# TEMPERATURE FIGURE-------------------------------------------------------------------------------------------------\n",
    "# Setup Figure \n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_context(\"notebook\", font_scale=2.0)\n",
    "sns.set_context( font_scale=1.5,rc={'lines.markeredgewidth': 0.1})\n",
    "sns.plt.figure(figsize=[10,6])\n",
    "sns.plt.title('GHD-Core ('+np.str(np.min(base_period))+'-'+np.str(np.max(base_period))+', JJA)',fontsize=25)\n",
    "sns.regplot(\"Temp\",\"GHD\",df_siteclim,scatter=True,marker='o')\n",
    "sns.plt.ylim(limit_ghd)\n",
    "sns.plt.xlim(limit_temp)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df_siteclim.Temp,df_siteclim.GHD)\n",
    "R2 = np.round(r_value**2,decimals=3); pval = np.round(p_value, decimals=5); beta = np.round(slope,decimals=3)\n",
    "sns.plt.annotate(\"R2=\"+np.str(R2)+\", beta=\"+np.str(beta)+\", p=\"+np.str(pval),\\\n",
    "                     xy=(0.05,0.95),xycoords=\"axes fraction\",fontsize=15) \n",
    "sns.plt.tight_layout\n",
    "sns.plt.savefig('../figures/step03/ghdcore.regress.temp.century.'+np.str(np.min(base_period))+ \\\n",
    "                    '-'+np.str(np.max(base_period))+'.svg', format='svg', dpi=300) # vector graphics for adobe illustrator   \n",
    "\n",
    "# PRECIPITATION FIGURE-------------------------------------------------------------------------------------------------\n",
    "# Setup Figure \n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_context(\"notebook\", font_scale=2.0)\n",
    "sns.set_context( font_scale=1.5,rc={'lines.markeredgewidth': 0.1})\n",
    "sns.plt.figure(figsize=[10,6])\n",
    "sns.plt.title('GHD-Core ('+np.str(np.min(base_period))+'-'+np.str(np.max(base_period))+', JJA)',fontsize=25)\n",
    "sns.regplot(\"Prec\",\"GHD\",df_siteclim,scatter=True,marker='o')\n",
    "sns.plt.ylim(limit_ghd)\n",
    "sns.plt.xlim(limit_prec)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df_siteclim.Prec,df_siteclim.GHD)\n",
    "R2 = np.round(r_value**2,decimals=3); pval = np.round(p_value, decimals=5); beta = np.round(slope,decimals=3)\n",
    "sns.plt.annotate(\"R2=\"+np.str(R2)+\", beta=\"+np.str(beta)+\", p=\"+np.str(pval),\\\n",
    "                     xy=(0.05,0.95),xycoords=\"axes fraction\",fontsize=15) \n",
    "sns.plt.tight_layout\n",
    "sns.plt.savefig('../figures/step03/ghdcore.regress.prec.century.'+np.str(np.min(base_period))+ \\\n",
    "                    '-'+np.str(np.max(base_period))+'.svg', format='svg', dpi=300) # vector graphics for adobe illustrator   \n",
    "\n",
    "# PDSI FIGURE----------------------------------------------------------------------------------------------------------\n",
    "# Setup Figure \n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_context(\"notebook\", font_scale=2.0)\n",
    "sns.set_context( font_scale=1.5,rc={'lines.markeredgewidth': 0.1})\n",
    "sns.plt.figure(figsize=[10,6])\n",
    "sns.plt.title('GHD-Core ('+np.str(np.min(base_period))+'-'+np.str(np.max(base_period))+', JJA)',fontsize=25)\n",
    "sns.regplot(\"PDSI\",\"GHD\",df_siteclim,scatter=True,marker='o')\n",
    "sns.plt.ylim(limit_ghd)\n",
    "sns.plt.xlim(limit_pdsi)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df_siteclim.PDSI,df_siteclim.GHD)\n",
    "R2 = np.round(r_value**2,decimals=3); pval = np.round(p_value, decimals=5); beta = np.round(slope,decimals=3)\n",
    "sns.plt.annotate(\"R2=\"+np.str(R2)+\", beta=\"+np.str(beta)+\", p=\"+np.str(pval),\\\n",
    "                     xy=(0.05,0.95),xycoords=\"axes fraction\",fontsize=15) \n",
    "sns.plt.tight_layout\n",
    "sns.plt.savefig('../figures/step03/ghdcore.regress.pdsi.century.'+np.str(np.min(base_period))+ \\\n",
    "                    '-'+np.str(np.max(base_period))+'.svg', format='svg', dpi=300) # vector graphics for adobe illustrator   \n",
    "\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct and plot the temperature correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CORRELATIONS: POINT BY POINT WITH TEMPERATURE----------------------------------------------------------\n",
    "rho_ghd_vs_temp = np.zeros((np.size(lat_temp),np.size(lon_temp)))*np.nan; \n",
    "\n",
    "for n_lat in enumerate(lat_temp):\n",
    "    for n_lon in enumerate(lon_temp):\n",
    "    \n",
    "        # Pull out Individual gridcell pdsi/temp/prec\n",
    "        temp_seas_cell = sub_temp[:,n_lat[0],n_lon[0]]\n",
    "\n",
    "        # Put in NaN if ocean areas (missing values)\n",
    "        if temp_seas_cell[0]>900:\n",
    "\n",
    "            rho_ghd_vs_temp[n_lat[0],n_lon[0]]  = np.nan\n",
    "        \n",
    "        # Calculate the correlation if a legitimate observation\n",
    "        else:   \n",
    "                             \n",
    "            # Spearman rank correlations: Temp\n",
    "            rho,pval = stats.spearmanr(temp_seas_cell,sub_ghd)    \n",
    "            rho_ghd_vs_temp[n_lat[0],n_lon[0]]  = rho\n",
    "            \n",
    "# Mapping Parameters------------------------------------------------------------------------------\n",
    "# Set Map Limits and coordinates for mapping\n",
    "lon_map = lon_temp; lat_map = lat_temp;\n",
    "\n",
    "lonlim=np.array([-10,16]);\n",
    "latlim=np.array([35,60]);\n",
    "#lonlim=np.array([np.min(lon_temp),np.max(lon_temp)]);\n",
    "#latlim=np.array([np.min(lat_temp),np.max(lat_temp)]);\n",
    "\n",
    "# Regional Projections\n",
    "proj_txt='cyl'      # Equidistant cyclindrical\n",
    "lon_map, lat_map = np.meshgrid(lon_map, lat_map)\n",
    "\n",
    "site_color = np.float64([0,0,0])/255\n",
    "\n",
    "# Title info\n",
    "fontdict = {'fontsize': 18}\n",
    "\n",
    "# Map of Temperature Correlations\n",
    "title_txt = 'GHD-Core vs JJA Temp (rho), ('+np.str(np.min(base_period))+'-'+np.str(np.max(base_period))+')'\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "# (2) SETUP PROJECTION\n",
    "m = Basemap(projection=proj_txt,resolution='l',\\\n",
    "        llcrnrlon=np.min(lonlim),llcrnrlat=np.min(latlim),\\\n",
    "        urcrnrlon=np.max(lonlim),urcrnrlat=np.max(latlim))\n",
    "# (3) DRAW BOUNDARIES AND PARALLELS (IF DESIRED)\n",
    "m.drawcoastlines()\n",
    "m.drawstates()\n",
    "m.drawcountries()\n",
    "# draw parallels.\n",
    "parallels = np.arange(0.,90,10.)\n",
    "# draw meridians\n",
    "meridians = np.arange(180.,360.,10.)\n",
    "# (4) COMPUTE MAP PROJECTION COORDINATES\n",
    "x, y = m(lon_map, lat_map) # compute map proj coordinates.\n",
    "# (5) DRAW FILLED CONTOURS, BOUNDARY, AND LAND-SEA MASK\n",
    "clevs = [-.9,-.8,-.7,-.6,-.5,-.4,-.3,-.2,-.1,0,.1,.2,.3,.4,.5,.6,.7,.8,.9]; clevs=np.asarray(clevs); clevs=clevs*1\n",
    "cs = m.contourf(x,y,rho_ghd_vs_temp,clevs,cmap=plt.cm.RdBu,extend=\"both\")\n",
    "m.drawmapboundary(fill_color='#99ffff')\n",
    "m.drawlsmask(land_color='w', ocean_color=np.float64([209,230,241])/255)\n",
    "# (6) PLOT RECTANGLE OVER THE REGION\n",
    "plot_rectangle(m, lonmin, lonmax, latmin, latmax) \n",
    "#    # (7) DRAW SITE LOCATION\n",
    "#    x_loc, y_loc = m(lon_site,lat_site)\n",
    "#    m.scatter(x_loc,y_loc,65,marker='o',color=site_color)\n",
    "# (8) ADD COLORBAR AND TITLE\n",
    "cbar = m.colorbar(cs,location='bottom',pad=\"5%\")\n",
    "cbar.set_label('Correlation',fontsize=18)\n",
    "plt.title(title_txt,fontdict)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "# (9) SAVE TO OUTPUT\n",
    "plt.show()\n",
    "out_txt = '../figures/step03/corrmap.ghdcore.vs.tmpJJA.'+np.str(np.min(base_period))+'-'+np.str(np.max(base_period))+'.eps'\n",
    "fig.savefig(out_txt, format='eps', dpi=150) # vector graphics for adobe illustrator           \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct and plot the precipitation correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CORRELATIONS: POINT BY POINT WITH PRECIPITATION----------------------------------------------------------\n",
    "rho_ghd_vs_prec = np.zeros((np.size(lat_prec),np.size(lon_prec)))*np.nan; \n",
    "\n",
    "for n_lat in enumerate(lat_prec):\n",
    "    for n_lon in enumerate(lon_prec):\n",
    "    \n",
    "        # Pull out Individual gridcell pdsi/temp/prec\n",
    "        prec_seas_cell = sub_prec[:,n_lat[0],n_lon[0]]\n",
    "\n",
    "        # Put in NaN if ocean areas (missing values)\n",
    "        if prec_seas_cell[0]>900:\n",
    "\n",
    "            rho_ghd_vs_prec[n_lat[0],n_lon[0]]  = np.nan\n",
    "        \n",
    "        # Calculate the correlation if a legitimate observation\n",
    "        else:   \n",
    "                             \n",
    "            # Spearman rank correlations: Temp\n",
    "            rho,pval = stats.spearmanr(prec_seas_cell,sub_ghd)    \n",
    "            rho_ghd_vs_prec[n_lat[0],n_lon[0]]  = rho\n",
    "            \n",
    "# Mapping Parameters------------------------------------------------------------------------------\n",
    "# Set Map Limits and coordinates for mapping\n",
    "lon_map = lon_prec; lat_map = lat_prec;\n",
    "\n",
    "lonlim=np.array([-10,16]);\n",
    "latlim=np.array([35,60]);\n",
    "\n",
    "# Regional Projections\n",
    "proj_txt='cyl'      # Equidistant cyclindrical\n",
    "lon_map, lat_map = np.meshgrid(lon_map, lat_map)\n",
    "\n",
    "site_color = np.float64([0,0,0])/255\n",
    "\n",
    "# Title info\n",
    "fontdict = {'fontsize': 18}\n",
    "\n",
    "# Map of Temperature Correlations\n",
    "title_txt = 'GHD-Core vs JJA Prec (rho), ('+np.str(np.min(base_period))+'-'+np.str(np.max(base_period))+')'\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "# (2) SETUP PROJECTION\n",
    "m = Basemap(projection=proj_txt,resolution='l',\\\n",
    "        llcrnrlon=np.min(lonlim),llcrnrlat=np.min(latlim),\\\n",
    "        urcrnrlon=np.max(lonlim),urcrnrlat=np.max(latlim))\n",
    "# (3) DRAW BOUNDARIES AND PARALLELS (IF DESIRED)\n",
    "m.drawcoastlines()\n",
    "m.drawstates()\n",
    "m.drawcountries()\n",
    "# draw parallels.\n",
    "parallels = np.arange(0.,90,10.)\n",
    "# draw meridians\n",
    "meridians = np.arange(180.,360.,10.)\n",
    "# (4) COMPUTE MAP PROJECTION COORDINATES\n",
    "x, y = m(lon_map, lat_map) # compute map proj coordinates.\n",
    "# (5) DRAW FILLED CONTOURS, BOUNDARY, AND LAND-SEA MASK\n",
    "clevs = [-.9,-.8,-.7,-.6,-.5,-.4,-.3,-.2,-.1,0,.1,.2,.3,.4,.5,.6,.7,.8,.9]; clevs=np.asarray(clevs); clevs=clevs*1\n",
    "cs = m.contourf(x,y,rho_ghd_vs_prec,clevs,cmap=plt.cm.RdBu,extend=\"both\")\n",
    "m.drawmapboundary(fill_color='#99ffff')\n",
    "m.drawlsmask(land_color='w', ocean_color=np.float64([209,230,241])/255)\n",
    "# (6) PLOT RECTANGLE OVER THE REGION\n",
    "plot_rectangle(m, lonmin, lonmax, latmin, latmax) \n",
    "#    # (7) DRAW SITE LOCATION\n",
    "#    x_loc, y_loc = m(lon_site,lat_site)\n",
    "#    m.scatter(x_loc,y_loc,65,marker='o',color=site_color)\n",
    "# (8) ADD COLORBAR AND TITLE\n",
    "cbar = m.colorbar(cs,location='bottom',pad=\"5%\")\n",
    "cbar.set_label('Correlation',fontsize=18)\n",
    "plt.title(title_txt,fontdict)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "# (9) SAVE TO OUTPUT\n",
    "plt.show()\n",
    "out_txt = '../figures/step03/corrmap.ghdcore.vs.preJJA.'+np.str(np.min(base_period))+'-'+np.str(np.max(base_period))+'.eps'\n",
    "fig.savefig(out_txt, format='eps', dpi=150) # vector graphics for adobe illustrator           \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct and plot the PDSI correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CORRELATIONS: POINT BY POINT WITH PDSI----------------------------------------------------------\n",
    "rho_ghd_vs_pdsi = np.zeros((np.size(lat_pdsi),np.size(lon_pdsi)))*np.nan; \n",
    "\n",
    "for n_lat in enumerate(lat_pdsi):\n",
    "    for n_lon in enumerate(lon_pdsi):\n",
    "    \n",
    "        # Pull out Individual gridcell pdsi/temp/prec\n",
    "        pdsi_seas_cell = sub_pdsi[:,n_lat[0],n_lon[0]]\n",
    "\n",
    "        # Put in NaN if ocean areas (missing values)\n",
    "        if np.isnan(pdsi_seas_cell[0])==1:\n",
    "\n",
    "            rho_ghd_vs_pdsi[n_lat[0],n_lon[0]]  = np.nan\n",
    "        \n",
    "        # Calculate the correlation if a legitimate observation\n",
    "        else:   \n",
    "                             \n",
    "            # Spearman rank correlations: Temp\n",
    "            rho,pval = stats.spearmanr(pdsi_seas_cell,sub_ghd)    \n",
    "            rho_ghd_vs_pdsi[n_lat[0],n_lon[0]]  = rho\n",
    "            \n",
    "# Mapping Parameters------------------------------------------------------------------------------\n",
    "# Set Map Limits and coordinates for mapping\n",
    "lon_map = lon_pdsi; lat_map = lat_pdsi;\n",
    "\n",
    "lonlim=np.array([-10,16]);\n",
    "latlim=np.array([35,60]);\n",
    "\n",
    "# Regional Projections\n",
    "proj_txt='cyl'      # Equidistant cyclindrical\n",
    "lon_map, lat_map = np.meshgrid(lon_map, lat_map)\n",
    "\n",
    "site_color = np.float64([0,0,0])/255\n",
    "\n",
    "# Title info\n",
    "fontdict = {'fontsize': 18}\n",
    "\n",
    "# Map of Temperature Correlations\n",
    "title_txt = 'GHD-Core vs JJA PDSI (rho), ('+np.str(np.min(base_period))+'-'+np.str(np.max(base_period))+')'\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "# (2) SETUP PROJECTION\n",
    "m = Basemap(projection=proj_txt,resolution='l',\\\n",
    "        llcrnrlon=np.min(lonlim),llcrnrlat=np.min(latlim),\\\n",
    "        urcrnrlon=np.max(lonlim),urcrnrlat=np.max(latlim))\n",
    "# (3) DRAW BOUNDARIES AND PARALLELS (IF DESIRED)\n",
    "m.drawcoastlines()\n",
    "m.drawstates()\n",
    "m.drawcountries()\n",
    "# draw parallels.\n",
    "parallels = np.arange(0.,90,10.)\n",
    "# draw meridians\n",
    "meridians = np.arange(180.,360.,10.)\n",
    "# (4) COMPUTE MAP PROJECTION COORDINATES\n",
    "x, y = m(lon_map, lat_map) # compute map proj coordinates.\n",
    "# (5) DRAW FILLED CONTOURS, BOUNDARY, AND LAND-SEA MASK\n",
    "clevs = [-.9,-.8,-.7,-.6,-.5,-.4,-.3,-.2,-.1,0,.1,.2,.3,.4,.5,.6,.7,.8,.9]; clevs=np.asarray(clevs); clevs=clevs*1\n",
    "cs = m.contourf(x,y,rho_ghd_vs_pdsi,clevs,cmap=plt.cm.RdBu,extend=\"both\")\n",
    "m.drawmapboundary(fill_color='#99ffff')\n",
    "m.drawlsmask(land_color='w', ocean_color=np.float64([209,230,241])/255)\n",
    "# (6) PLOT RECTANGLE OVER THE REGION\n",
    "plot_rectangle(m, lonmin, lonmax, latmin, latmax) \n",
    "#    # (7) DRAW SITE LOCATION\n",
    "#    x_loc, y_loc = m(lon_site,lat_site)\n",
    "#    m.scatter(x_loc,y_loc,65,marker='o',color=site_color)\n",
    "# (8) ADD COLORBAR AND TITLE\n",
    "cbar = m.colorbar(cs,location='bottom',pad=\"5%\")\n",
    "cbar.set_label('Correlation',fontsize=18)\n",
    "plt.title(title_txt,fontdict)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "# (9) SAVE TO OUTPUT\n",
    "plt.show()\n",
    "out_txt = '../figures/step03/corrmap.ghdcore.vs.pdsi.'+np.str(np.min(base_period))+'-'+np.str(np.max(base_period))+'.eps'\n",
    "fig.savefig(out_txt, format='eps', dpi=150) # vector graphics for adobe illustrator           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
